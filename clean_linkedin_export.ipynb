{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean a JSON LinkedIn profile file\n",
    "Takes a JSON file that was scrapped with data from LinkedIn and makes it ready to be used. Converts the _position_ titles, normalizes all the text cases. This should be used on a raw JSON scrapped file as first set before adapting it to Dropcontact format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import pandas\n",
    "import pathlib\n",
    "import secrets\n",
    "import datetime\n",
    "from itertools import chain\n",
    "from nltk.tokenize import LineTokenizer\n",
    "from marketing_data_cleaning import DATA_FOLDER_PATH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def chain_for_dataframe(filename, write_file=True):\n",
    "    \"\"\"\n",
    "    Regroups subsets of dictionnaries together\n",
    "\n",
    "    >>> [[{...}], [{...}]]\n",
    "    ... [{...}, {...}]\n",
    "    \"\"\"\n",
    "    with open(DATA_FOLDER_PATH / filename, mode='r', encoding='utf-8') as f:\n",
    "        chained_values = list(chain(*json.load(f)))\n",
    "        df = pandas.DataFrame(chained_values)\n",
    "\n",
    "        if write_file:\n",
    "            df.to_json(\n",
    "                DATA_FOLDER_PATH / 'chained_output.json',\n",
    "                force_ascii=False,\n",
    "                orient='records'\n",
    "            )\n",
    "        return df\n",
    "\n",
    "\n",
    "df = chain_for_dataframe(DATA_FOLDER_PATH / 'inputs/v8.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                                     765\n",
       "unique                                     31\n",
       "top       (16) ASSADIA : personnes | LinkedIn\n",
       "freq                                      155\n",
       "Name: company, dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['company'].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean main data\n",
    "Make cases title case (especially first_name and last_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = LineTokenizer()\n",
    "\n",
    "for item in df.itertuples():\n",
    "    if item.company_description is not None:\n",
    "        tokens = tokenizer.tokenize(item.company_description) \n",
    "        df.loc[item.Index, 'company_description'] = ' '.join(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_names(value):\n",
    "    return str(value).lower().title()\n",
    "\n",
    "\n",
    "columns_to_normalize = ['last_name', 'first_name', 'full_name']\n",
    "\n",
    "for column in columns_to_normalize:\n",
    "    df[column] = df[column].apply(normalize_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_company(value):\n",
    "    return_value = None\n",
    "    result = re.match(r'^\\(\\d+\\)\\s(.*)\\s?\\:', str(value))\n",
    "    if result:\n",
    "        return_value = result.group(1).strip().upper()\n",
    "    return return_value or value.upper()\n",
    "\n",
    "df['company'] = df['company'].apply(extract_company)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for item in df.itertuples():\n",
    "#     regexes = [\n",
    "#         r'chez\\s?\\w+',\n",
    "#         rf'{item.company}'\n",
    "#     ]\n",
    "\n",
    "#     new_value = None\n",
    "#     for regex in regexes:\n",
    "#         result = re.search(regex, item.position)\n",
    "#         if result is None:\n",
    "#             continue\n",
    "#         new_value = re.sub(regex, '', item.position)\n",
    "#         df.loc[item.Index, 'position'] = new_value or item.position\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=['first_name', 'last_name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values('last_name')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Airtable adapter\n",
    "Adapts a Dropcontact adapated CSV file by cleaning and correcting the column names so that it can eventually be uploaded to an Airtable base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS_TO_ADAPT = {\n",
    "    'linkedin': 'LinkedIn',\n",
    "    'courtesy_title': 'Civilité',\n",
    "    'first_name': 'Prénom',\n",
    "    'last_name': 'Nom',\n",
    "    'full_name': 'Nom complet',\n",
    "    'position': 'Poste',\n",
    "    'company': 'Entreprise',\n",
    "    'company_linkedin': 'Company LinkedIn',\n",
    "    'enriched': 'Statut enrichissement',\n",
    "    'email': 'Email',\n",
    "    'website': 'Site entreprise',\n",
    "    'company_metadata': 'Company metadata',\n",
    "    'company_members': 'Company members',\n",
    "    'company_description': 'Description'\n",
    "}\n",
    "airtable_df = df.rename(columns=COLUMNS_TO_ADAPT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "interesting_positions = ['directeur', 'directrice', 'ceo', 'dirigeant', 'ceo', 'founder', 'responsable', 'manager', 'founder', 'fondateur', 'fondatrice']\n",
    "\n",
    "def test_position(value):\n",
    "    result = False\n",
    "\n",
    "    if value is None or value == '' or value == '-':\n",
    "        return result\n",
    "\n",
    "    for position in interesting_positions:\n",
    "        if position in value.lower():\n",
    "            result = True\n",
    "            break\n",
    "    return result\n",
    "\n",
    "airtable_df['of_interest'] = airtable_df['Poste'].map(test_position)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Entreprise', 'Description', 'Company LinkedIn', 'Company metadata',\n",
       "       'Company members', 'Statut enrichissement', 'LinkedIn', 'Nom complet',\n",
       "       'Site entreprise', 'Poste', 'Prénom', 'Nom', 'source', 'of_interest'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airtable_df = airtable_df[['Civilité', 'Prénom', 'Nom', 'Nom complet', 'Poste', 'LinkedIn', 'Entreprise', 'Company LinkedIn',\n",
    "                           'Statut enrichissement', 'Site entreprise', 'Company metadata', 'Company members', 'Description']]\n",
    "\n",
    "airtable_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = datetime.datetime.now().strftime('%Y-%m-%d %H:%M')\n",
    "filename = f\"v_{d.replace(' ', '_').replace(':', '-')}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "airtable_df.to_csv(DATA_FOLDER_PATH / f'db/{filename}.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
