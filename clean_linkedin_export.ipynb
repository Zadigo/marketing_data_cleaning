{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean a JSON LinkedIn profile file\n",
    "Takes a JSON file that was scrapped with data from LinkedIn and makes it ready to be used. Converts the _position_ titles, normalizes all the text cases. This should be used on a raw JSON scrapped file as first set before adapting it to Dropcontact format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import pandas\n",
    "from marketing_data_cleaning import DATA_FOLDER_PATH\n",
    "from itertools import chain\n",
    "import pathlib\n",
    "import secrets\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def chain_for_dataframe(filename, write_file=True):\n",
    "    \"\"\"\n",
    "    Regroups subsets of dictionnaries together\n",
    "\n",
    "    >>> [[{...}], [{...}]]\n",
    "    ... [{...}, {...}]\n",
    "    \"\"\"\n",
    "    with open(DATA_FOLDER_PATH / filename, mode='r', encoding='utf-8') as f:\n",
    "        chained_values = list(chain(*json.load(f)))\n",
    "        df = pandas.DataFrame(chained_values)\n",
    "\n",
    "        if write_file:\n",
    "            df.to_json(\n",
    "                DATA_FOLDER_PATH / 'chained_output.json',\n",
    "                force_ascii=False,\n",
    "                orient='records'\n",
    "            )\n",
    "        return df\n",
    "\n",
    "\n",
    "df = chain_for_dataframe(DATA_FOLDER_PATH / 'inputs/v8.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                                      152\n",
       "unique                                       5\n",
       "top       (13) Glastint : personnes | LinkedIn\n",
       "freq                                        56\n",
       "Name: company, dtype: object"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['company'].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean main data\n",
    "Make cases title case (especially first_name and last_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_names(value):\n",
    "    return str(value).lower().title()\n",
    "\n",
    "\n",
    "columns_to_normalize = ['last_name', 'first_name', 'full_name']\n",
    "\n",
    "for column in columns_to_normalize:\n",
    "    df[column] = df[column].apply(normalize_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_company(value):\n",
    "    result = re.match(r'^\\(\\d+\\)\\s(.*)\\s?\\:', str(value))\n",
    "    if result:\n",
    "        return result.group(1).strip()\n",
    "    return value\n",
    "\n",
    "\n",
    "df['company'] = df['company'].apply(extract_company)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for item in df.itertuples():\n",
    "#     regexes = [\n",
    "#         r'chez\\s?\\w+',\n",
    "#         rf'{item.company}'\n",
    "#     ]\n",
    "\n",
    "#     new_value = None\n",
    "#     for regex in regexes:\n",
    "#         result = re.search(regex, item.position)\n",
    "#         if result is None:\n",
    "#             continue\n",
    "#         new_value = re.sub(regex, '', item.position)\n",
    "#         df.loc[item.Index, 'position'] = new_value or item.position\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=['first_name', 'last_name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values('last_name')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Airtable adapter\n",
    "Adapts a Dropcontact adapated CSV file by cleaning and correcting the column names so that it can eventually be uploaded to an Airtable base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS_TO_ADAPT = {\n",
    "    'linkedin': 'LinkedIn',\n",
    "    'courtesy_title': 'Civilité',\n",
    "    'first_name': 'Prénom',\n",
    "    'last_name': 'Nom',\n",
    "    'full_name': 'Nom complet',\n",
    "    'position': 'Poste',\n",
    "    'company': 'Entreprise',\n",
    "    'company_linkedin': 'Company LinkedIn',\n",
    "    'enriched': 'Statut enrichissement',\n",
    "    'email': 'Email',\n",
    "    'website': 'Site entreprise',\n",
    "    'company_metadata': 'Company metadata',\n",
    "    'company_members': 'Company members',\n",
    "    'company_description': 'Description'\n",
    "}\n",
    "airtable_df = df.rename(columns=COLUMNS_TO_ADAPT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = datetime.datetime.now().strftime('%Y-%m-%d %H:%M')\n",
    "filename = f\"v_{d.replace(' ', '_').replace(':', '-')}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "airtable_df.to_csv(DATA_FOLDER_PATH / f'db/{filename}.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
